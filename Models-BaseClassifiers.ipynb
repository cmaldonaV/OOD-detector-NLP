{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import transformers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_hub as hub\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import cuda,nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\camilo\\anaconda3\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: packaging in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: six in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "!pip install transformers\n",
    "# SEEDS \n",
    "# [3,42,107,33,17]\n",
    "seed = 3\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed)\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed)\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "dataset = 'clinc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22500 entries, 17933 to 5994\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text_raw  22500 non-null  object\n",
      " 1   label     22500 non-null  object\n",
      " 2   group     22500 non-null  object\n",
      " 3   text      22500 non-null  object\n",
      " 4   class     22500 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "path_data = '\\\\Users\\\\Camilo\\\\Desktop\\\\tesis\\\\codes\\\\data\\\\'\n",
    "df = pd.read_csv(path_data+dataset+'Data.csv', delimiter='@')\n",
    "df = df.sample(frac=1)\n",
    "df.text = df.text.apply(lambda x: str(x))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larges of percentiles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.,  4.,  5.,  6., 15.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df['text'].apply(lambda x: len(str(x).split()))\n",
    "print('Larges of percentiles')\n",
    "np.percentile(data, [25, 50, 75,90,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(df,dim=50):\n",
    "    docs = df.text.values\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(docs)\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    # load the whole embedding into memory\n",
    "    embeddings_index = dict()\n",
    "    f = open('\\\\Users\\\\Camilo\\\\Desktop\\\\tesis\\\\codes\\\\embs\\\\glove.twitter.27B.'+str(dim)+'d.txt')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size, dim))\n",
    "    for word, i in t.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    emb_m = torch.tensor(embedding_matrix)\n",
    "    embeds = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=50,_weight=emb_m)\n",
    "\n",
    "    return embeds,t,embeddings_index\n",
    "\n",
    "def emb_Glove(df,max_length,t,emb):\n",
    "    docs = df.text.values\n",
    "    outs = df['class'].values\n",
    "    encoded_docs = t.texts_to_sequences(docs)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    lookup_tensor = torch.tensor(padded_docs, dtype=torch.long)\n",
    "    data_embed = emb(lookup_tensor)\n",
    "    y = torch.tensor(outs, dtype=torch.int16)\n",
    "    return  data_embed.to(torch.float32),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193515 word vectors.\n"
     ]
    }
   ],
   "source": [
    "emb,tok,voc = loadGlove(df[df.group == 'train'],dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = emb_Glove(df[df.group == 'train'],20,tok,emb)\n",
    "X_val,y_val = emb_Glove(df[df.group == 'val'],20,tok,emb)\n",
    "X_test,y_test = emb_Glove(df[df.group == 'test'],20,tok,emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embGlove(df,max_length):\n",
    "    docs = df.text.values\n",
    "    outs = df['class'].values\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(docs)\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    encoded_docs = t.texts_to_sequences(docs)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "    # load the whole embedding into memory\n",
    "    embeddings_index = dict()\n",
    "    f = open('\\\\Users\\\\Camilo\\\\Desktop\\\\tesis\\\\codes\\\\embs\\\\glove.twitter.27B.50d.txt')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = np.zeros((vocab_size, 50))\n",
    "    for word, i in t.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    emb_m = torch.tensor(embedding_matrix)\n",
    "    # loaded emb matrix\n",
    "    embeds = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=50,_weight=emb_m)\n",
    "    # embedding docs\n",
    "    lookup_tensor = torch.tensor(padded_docs, dtype=torch.long)\n",
    "  \n",
    "    data_embed = embeds(lookup_tensor)\n",
    "    y = torch.tensor(outs, dtype=torch.int16)\n",
    "    return data_embed.to(torch.float32),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193515 word vectors.\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = embGlove(df[df.group == 'train'],20)\n",
    "#X_val,y_val = embGlove(df[df.group == 'val'],20)\n",
    "#X_test,y_test = embGlove(df[df.group == 'test'],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_USE(df,emb):\n",
    "  docs = df.text.values\n",
    "  v = emb(docs).numpy()\n",
    "  return torch.tensor(v,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using C:\\Users\\Camilo\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n",
      "INFO:absl:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/5: 310.04MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/5, Total size: 577.10MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n"
     ]
    }
   ],
   "source": [
    "emb_use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "emb_use_large = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12000, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = emb_USE(df[df.group == 'train'],emb_use) \n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12000, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_large = emb_USE(df[df.group == 'train'],emb_use_large) \n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrainedModel = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(preTrainedModel)\n",
    "bert_model = BertModel.from_pretrained(preTrainedModel)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.sentence = dataframe.text.values\n",
    "        #self.targets = self.data['class'].values\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.sentence)\n",
    "    def __getitem__(self, index):\n",
    "        sentence = str(self.sentence[index])\n",
    "        sentence = \" \".join(sentence.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids'] #Ids del vocabulario\n",
    "        mask = inputs['attention_mask'] #Mascaras para definir donde la atencion deberia ver\n",
    "        token_type_ids = inputs[\"token_type_ids\"] #requerido pero no utilizado\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
    "            #'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "def validation(epoch,val_loader):\n",
    "    model.eval()\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(val_loader, 0),total = len(val_loader)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            #fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            #fin_outputs.extend((outputs).squeeze(1).cpu().detach().numpy())\n",
    "            fin_outputs.extend((outputs))\n",
    "    \n",
    "    return (fin_outputs)#, np.array(fin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Camilo\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens = []\n",
    "for txt in df.text:\n",
    "  toks = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(toks))\n",
    "\n",
    "sns.distplot(token_lens)\n",
    "print(np.max(token_lens))\n",
    "plt.xlabel('Token count');\n",
    "device = 'cuda:0' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253af518a9634735a42ea5863f5605bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 20 # Len in function of dataset\n",
    "training_set = CustomDataset(df[df.group == 'train'], tokenizer, MAX_LEN)\n",
    "\n",
    "TEST_BATCH_SIZE = 8\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# Dataloaders for pytorch\n",
    "\n",
    "training_loader = DataLoader(training_set, **test_params)\n",
    "model = bert_model\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)\n",
    "\n",
    "for epoch in range(1):\n",
    "    outputs = validation(epoch,training_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Text(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 128, kernel_size=(3, 50), stride=(1, 1))\n",
       "    (1): Conv2d(1, 128, kernel_size=(4, 50), stride=(1, 1))\n",
       "    (2): Conv2d(1, 128, kernel_size=(5, 50), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=384, out_features=150, bias=True)\n",
       "  (soft): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = CNN_Text(X_train.shape,len(df[df.group == 'train']['class'].unique()),0.2)\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    def __init__(self, inShape,outClasses,dp):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        V = inShape[1]\n",
    "        D = inShape[2]\n",
    "        C = outClasses\n",
    "        Ci = 1\n",
    "        Co = 128\n",
    "        Ks = [3,4,5]\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "        self.soft = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        out = self.soft(logit)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def train(train_iter, dev_iter, model, opt,epochs,Loss):\n",
    "    model.cuda()\n",
    "    optimizer = opt\n",
    "    steps = 0\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    log_interval=1\n",
    "    test_interval=100\n",
    "    early_stop=100\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        for batch in train_iter:\n",
    "            model.train()\n",
    "            feature, target = batch.text, batch.label\n",
    "            feature.t_(), target.sub_(1)  # batch first, index align\n",
    "            feature, target = feature.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            logit = model(feature)\n",
    "            loss = Loss(logit, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps += 1\n",
    "            if steps % log_interval == 0:\n",
    "                corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "                accuracy = 100.0 * corrects/batch.batch_size\n",
    "                sys.stdout.write(\n",
    "                    '\\rBatch[{}] - loss: {:.6f}  acc: {:.4f}%({}/{})'.format(steps, \n",
    "                                                                             loss.item(), \n",
    "                                                                             accuracy.item(),\n",
    "                                                                             corrects.item(),\n",
    "                                                                             batch.batch_size))\n",
    "            if steps % test_interval == 0:\n",
    "                dev_acc = eval(dev_iter, model, Loss)\n",
    "                if dev_acc > best_acc:\n",
    "                    best_acc = dev_acc\n",
    "                    last_step = steps\n",
    "                    #if args.save_best:\n",
    "                    #    save(model, args.save_dir, 'best', steps)\n",
    "                else:\n",
    "                    if steps - last_step >= early_stop:\n",
    "                        print('early stop by {} steps.'.format(early_stop))\n",
    "            #elif steps % args.save_interval == 0:\n",
    "            #    save(model, args.save_dir, 'snapshot', steps)\n",
    "\n",
    "\n",
    "def eval(data_iter, model, Loss):\n",
    "    model.eval()\n",
    "    corrects, avg_loss = 0, 0\n",
    "    for batch in data_iter:\n",
    "        feature, target = batch.text, batch.label\n",
    "        feature.t_(), target.sub_(1)  # batch first, index align\n",
    "        feature, target = feature.cuda(), target.cuda()\n",
    "        logit = model(feature)\n",
    "        loss = Loss(logit, target, size_average=False)\n",
    "        avg_loss += loss.item()\n",
    "        corrects += (torch.max(logit, 1)\n",
    "                     [1].view(target.size()).data == target.data).sum()\n",
    "\n",
    "    size = len(data_iter.dataset)\n",
    "    avg_loss /= size\n",
    "    accuracy = 100.0 * corrects/size\n",
    "    print('\\nEvaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, \n",
    "                                                                       accuracy, \n",
    "                                                                       corrects, \n",
    "                                                                       size))\n",
    "    return accuracy\n",
    "\n",
    "def save(model, save_dir, save_prefix, steps):\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_prefix = os.path.join(save_dir, save_prefix)\n",
    "    save_path = '{}_steps_{}.pt'.format(save_prefix, steps)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "def customData(X,y):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropOut = 0.0\n",
    "batch_size = 128\n",
    "model = CNN_Text(X_train.shape,len(df[df.group == 'train']['class'].unique()),dropOut)\n",
    "optimizer =  torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "epochs = 200\n",
    "train_iter = customData(X_train,y_train)\n",
    "dev_iter = customData(X_val,y_val)\n",
    "train(train_iter, dev_iter, model, optimizer,epochs,Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FF network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFnet(nn.Module):\n",
    "    def __init__(self,inputs_shape,k_classes):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.net = nn.Sequential( #sequential operation\n",
    "            nn.Linear(inputs_shape[1], 2048), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048,1024), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, k_classes), \n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "def fit_FFnet(x, y, model, opt, loss_fn, epochs = 10000):\n",
    "    \"\"\"Generic function for training a model \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        loss = loss_fn(model(x), y) \n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        if(epoch % 500 == 0):\n",
    "            print('loss: ',loss)\n",
    "            print('ep: ', epoch)\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "     pred = torch.argmax(y_hat, dim=1)\n",
    "     return (pred == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFnet(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=256, out_features=150, bias=True)\n",
      "    (12): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 1.16 GiB already allocated; 0 bytes free; 1.21 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-812402b32ca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-254091b3ccea>\u001b[0m in \u001b[0;36mfit_v2\u001b[1;34m(x, y, model, opt, loss_fn, epochs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;34m\"\"\"Generic function for training a model \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 1.16 GiB already allocated; 0 bytes free; 1.21 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "X_train = emb_USE(df[df.group == 'train'],emb_use_large) \n",
    "Y_train = torch.tensor(df[df.group == 'train']['class'].values)\n",
    "k_classes = len(df['class'].unique())\n",
    "X_train=X_train.to(device)\n",
    "Y_train=Y_train.to(device)\n",
    "\n",
    "model = FFnet(X_train.shape,k_classes)\n",
    "print(model)\n",
    "model.to(device) #moving the network to GPU\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "tic = time.time()\n",
    "l = fit_v2(X_train, Y_train, model, opt, loss_fn)\n",
    "print('Final loss', l)\n",
    "toc = time.time()\n",
    "print('Time taken', (toc - tic)/60.)\n",
    "\n",
    "X_val = emb_USE(df[df.group == 'val'],emb_use_large) \n",
    "X_val = X_val.to(device)\n",
    "y_val = torch.tensor(df[df.group == 'val']['class'].values)\n",
    "y_pred = model(X_val).cpu()\n",
    "print('Acc: ', accuracy(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common class missclasiffied\n",
      "class:  ['ENTY']  errors:  30\n",
      "class:  ['LOC']  errors:  23\n",
      "class:  ['HUM']  errors:  13\n",
      "class:  ['NUM']  errors:  9\n",
      "class:  ['DESC']  errors:  9\n",
      "Most common pair of missclasiffied\n",
      "class1:  ['LOC']  class2:  ['ENTY']  errors:  12\n",
      "class1:  ['ENTY']  class2:  ['LOC']  errors:  11\n",
      "class1:  ['ENTY']  class2:  ['NUM']  errors:  10\n",
      "class1:  ['NUM']  class2:  ['ENTY']  errors:  7\n",
      "class1:  ['HUM']  class2:  ['DESC']  errors:  7\n",
      "class1:  ['ENTY']  class2:  ['DESC']  errors:  6\n",
      "class1:  ['LOC']  class2:  ['HUM']  errors:  6\n",
      "class1:  ['DESC']  class2:  ['HUM']  errors:  6\n",
      "class1:  ['LOC']  class2:  ['NUM']  errors:  4\n",
      "class1:  ['HUM']  class2:  ['LOC']  errors:  3\n",
      "class1:  ['ENTY']  class2:  ['HUM']  errors:  3\n",
      "class1:  ['NUM']  class2:  ['LOC']  errors:  2\n",
      "class1:  ['HUM']  class2:  ['ENTY']  errors:  2\n",
      "class1:  ['DESC']  class2:  ['LOC']  errors:  2\n",
      "class1:  ['DESC']  class2:  ['ENTY']  errors:  1\n",
      "class1:  ['HUM']  class2:  ['NUM']  errors:  1\n",
      "class1:  ['LOC']  class2:  ['DESC']  errors:  1\n"
     ]
    }
   ],
   "source": [
    "def err_info(y,y_pred,pars=True):\n",
    "    targets = y\n",
    "    outputs = y_pred.detach().numpy()\n",
    "    sum = 0\n",
    "    errs = list()\n",
    "    pairs = list()\n",
    "    for i in range(outputs.shape[0]):\n",
    "        y_pred = np.where(outputs[i] == np.amax(outputs[i]))[0][0]\n",
    "        y = targets[i]\n",
    "        if (y == y_pred):\n",
    "            sum += 1.\n",
    "        else:\n",
    "            errs.append(int(y.numpy()))\n",
    "            pairs.append((int(y.numpy()),y_pred))\n",
    "    plt.hist(errs)\n",
    "    plt.show()\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.classes_ = np.load(path_data+dataset+'-classesEncoder.npy',allow_pickle=True)\n",
    "\n",
    "    print('Most common class missclasiffied')\n",
    "    for c,v in Counter(errs).most_common():\n",
    "        print('class: ',encoder.inverse_transform([c]),' errors: ',v)\n",
    "\n",
    "    print('Most common pair of missclasiffied')\n",
    "    if(pars):\n",
    "        for t,v in Counter(pairs).most_common():\n",
    "            c1,c2 = t\n",
    "            print('class1: ',encoder.inverse_transform([c1]),' class2: ',encoder.inverse_transform([c2]) ,' errors: ',v)\n",
    "    return errs\n",
    "\n",
    "errs = err_info(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[df.group == 'val']['class'].values,label='labels',alpha=.8, edgecolor='red')\n",
    "plt.hist(errs,label='errs',alpha=0.7, edgecolor='yellow')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
